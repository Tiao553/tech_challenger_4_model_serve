{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7d24a1",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o √† Metodologia de Previs√£o de Pre√ßo com LSTM e Indicadores T√©cnicos\n",
    "\n",
    "Este c√≥digo implementa uma metodologia moderna para previs√£o de pre√ßos de a√ß√µes no curt√≠ssimo prazo (intradia), utilizando redes neurais recorrentes (LSTM bidirecionais) em conjunto com uma ampla gama de indicadores t√©cnicos cl√°ssicos. A abordagem combina princ√≠pios tradicionais da an√°lise t√©cnica com t√©cnicas contempor√¢neas de aprendizado profundo.\n",
    "\n",
    "> **Importante**: Esta implementa√ß√£o est√° sendo aplicada inicialmente √† a√ß√£o `VALE3.SA`, da mineradora Vale, como uma **prova de conceito (PoC)**. A escolha se deve √† sua alta liquidez e relev√¢ncia no mercado brasileiro. A inten√ß√£o √©, ap√≥s valida√ß√£o da abordagem com esta a√ß√£o, **escalar a metodologia para outras a√ß√µes da bolsa** que apresentem perfil semelhante ou apresentem interesse estrat√©gico.\n",
    "\n",
    "A seguir, descrevemos os principais componentes da metodologia:\n",
    "\n",
    "### 1. **Aquisi√ß√£o de Dados**\n",
    "Utiliza-se a biblioteca `yfinance` para coletar dados intradi√°rios (com granularidade de 1 minuto) da a√ß√£o `VALE3.SA` por um per√≠odo de 7 dias. Os dados incluem colunas como `Open`, `High`, `Low`, `Close` e `Volume`.\n",
    "\n",
    "### 2. **Engenharia de Atributos T√©cnicos**\n",
    "A fun√ß√£o `add_technical_indicators` incorpora uma rica variedade de indicadores t√©cnicos ao conjunto de dados, dentre os quais se destacam:\n",
    "\n",
    "- **Indicadores de momentum**: RSI, Estoc√°stico, Oscilador Awesome.\n",
    "- **Indicadores de tend√™ncia**: MACD, ADX, CCI, M√©dia M√≥vel Exponencial.\n",
    "- **Indicadores de volatilidade**: Bandas de Bollinger, ATR.\n",
    "- **Indicadores de volume**: OBV, VWAP, √çndice de Acumula√ß√£o/Distribui√ß√£o.\n",
    "- **Caracter√≠sticas de candlestick**: corpo, sombras e amplitude do candle.\n",
    "\n",
    "Esses atributos auxiliam o modelo a captar padr√µes n√£o triviais no comportamento dos pre√ßos.\n",
    "\n",
    "### 3. **Normaliza√ß√£o e Sequenciamento**\n",
    "Os dados s√£o normalizados com `MinMaxScaler` e, em seguida, organizados em sequ√™ncias temporais (janelas deslizantes) com tamanho vari√°vel (ex. 24, 36, 60 minutos), de modo a alimentar a rede neural com informa√ß√µes hist√≥ricas para prever o pr√≥ximo valor de fechamento.\n",
    "\n",
    "### 4. **Estrutura do Modelo**\n",
    "O modelo preditivo √© uma rede neural do tipo **Bidirectional LSTM**, composta por duas camadas LSTM (com possibilidade de dropout), seguida de uma camada densa para sa√≠da √∫nica (pre√ßo futuro). A bidirecionalidade permite √† rede capturar rela√ß√µes tanto no sentido passado ‚Üí futuro quanto futuro ‚Üí passado.\n",
    "\n",
    "### 5. **Treinamento e Avalia√ß√£o**\n",
    "O modelo √© treinado com valida√ß√£o cruzada (via `validation_split`) e parada antecipada (`EarlyStopping`). Para cada combina√ß√£o de hiperpar√¢metros, calcula-se o erro m√©dio absoluto (MAE) e o erro quadr√°tico m√©dio da raiz (RMSE) com base em dados de teste.\n",
    "\n",
    "### 6. **Otimiza√ß√£o de Hiperpar√¢metros**\n",
    "A busca por melhores combina√ß√µes de hiperpar√¢metros √© feita atrav√©s de uma busca randomizada, onde m√∫ltiplas configura√ß√µes s√£o testadas automaticamente, e os resultados s√£o registrados para identifica√ß√£o do melhor desempenho.\n",
    "\n",
    "### 7. **Visualiza√ß√£o dos Resultados**\n",
    "Ap√≥s o melhor modelo ser identificado, suas previs√µes s√£o desnormalizadas e comparadas graficamente com os valores reais. O gr√°fico resultante mostra visualmente a capacidade preditiva do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "Essa metodologia visa conciliar o conhecimento consagrado dos mercados financeiros (an√°lise t√©cnica) com as potencialidades do aprendizado de m√°quina sequencial, oferecendo uma base robusta para previs√µes em cen√°rios de alta frequ√™ncia e curto prazo.\n",
    "\n",
    "O uso inicial da a√ß√£o VALE3 permite validar a robustez da abordagem com um ativo de grande liquidez. Uma vez confirmada a efic√°cia, a arquitetura ser√° reaproveitada e ajustada para outras a√ß√µes brasileiras, com foco na escalabilidade e reprodutibilidade do pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391512b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD, EMAIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.volume import VolumeWeightedAveragePrice\n",
    "from ta.momentum import StochasticOscillator, AwesomeOscillatorIndicator\n",
    "from ta.volume import VolumeWeightedAveragePrice, OnBalanceVolumeIndicator, AccDistIndexIndicator\n",
    "from ta.trend import CCIIndicator, ADXIndicator, EMAIndicator\n",
    "from ta.volatility import AverageTrueRange\n",
    "import random\n",
    "\n",
    "# --- Par√¢metros fixos ---\n",
    "\n",
    "symbol = 'VALE3.SA'\n",
    "period = '7d'\n",
    "interval = '1m'\n",
    "SEQ_LENGTH_DEFAULT = 24\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe4f2e",
   "metadata": {},
   "source": [
    "A fun√ß√£o `add_technical_indicators` √© respons√°vel por enriquecer um `DataFrame` de pre√ßos de a√ß√µes com uma ampla variedade de **indicadores t√©cnicos cl√°ssicos**, comumente utilizados em an√°lise t√©cnica para tomada de decis√£o no mercado financeiro.\n",
    "\n",
    "Essa fun√ß√£o assume que o `DataFrame` de entrada (`df`) cont√©m, pelo menos, as colunas: `Open`, `High`, `Low`, `Close`, e `Volume`.\n",
    "\n",
    "### Vis√£o Geral\n",
    "\n",
    "- **Objetivo:** Adicionar colunas com indicadores t√©cnicos calculados a partir dos pre√ßos hist√≥ricos da a√ß√£o.\n",
    "- **Pr√©-condi√ß√£o:** A coluna `'Close'` deve existir no `DataFrame`. Caso contr√°rio, uma exce√ß√£o ser√° lan√ßada.\n",
    "- **Tratamento de Erros:** Qualquer falha no c√°lculo dos indicadores resulta em uma exce√ß√£o com mensagem detalhada.\n",
    "\n",
    "---\n",
    "\n",
    "### Indicadores Adicionados\n",
    "\n",
    "Abaixo, listam-se os indicadores inclu√≠dos e seu prop√≥sito:\n",
    "\n",
    "#### 1. **Indicadores de Momentum**\n",
    "\n",
    "- `RSI`: √çndice de For√ßa Relativa com janela de 14 per√≠odos.\n",
    "- `Stoch_K` e `Stoch_D`: Oscilador Estoc√°stico %K e sua m√©dia m√≥vel %D.\n",
    "- `Awesome_Oscillator`: Mede a for√ßa do momentum com duas m√©dias m√≥veis simples (5 e 34).\n",
    "\n",
    "#### 2. **Indicadores de Tend√™ncia**\n",
    "\n",
    "- `MACD`, `MACD_signal`, `MACD_diff`: Conjunto completo de MACD (12, 26, 9), incluindo linha de sinal e histograma.\n",
    "- `CCI`: Commodity Channel Index com janela de 20 per√≠odos.\n",
    "- `ADX`, `ADX_pos`, `ADX_neg`: √çndice Direcional M√©dio (ADX), e componentes positivo e negativo, com janela de 14 per√≠odos.\n",
    "- `EMA_20`: M√©dia m√≥vel exponencial de 20 per√≠odos.\n",
    "\n",
    "#### 3. **Indicadores de Volatilidade**\n",
    "\n",
    "- `BB_upper`, `BB_middle`, `BB_lower`: Bandas de Bollinger (20 per√≠odos, 2 desvios padr√£o).\n",
    "- `ATR`: True Range M√©dio (Average True Range) com janela de 14 per√≠odos.\n",
    "\n",
    "#### 4. **Indicadores de Volume**\n",
    "\n",
    "- `OBV`: On-Balance Volume.\n",
    "- `AccDistIndex`: √çndice de Acumula√ß√£o/Distribui√ß√£o.\n",
    "- `VWAP`: Pre√ßo m√©dio ponderado por volume, com janela de 14 per√≠odos (calculado somente se todas as colunas requeridas estiverem presentes).\n",
    "\n",
    "#### 5. **Caracter√≠sticas do Candle**\n",
    "\n",
    "- `Candle_Body`: Corpo do candle (Close - Open).\n",
    "- `Candle_Range`: Amplitude do candle (High - Low).\n",
    "- `Upper_Shadow`: Sombra superior (High - max(Open, Close)).\n",
    "- `Lower_Shadow`: Sombra inferior (min(Open, Close) - Low).\n",
    "\n",
    "---\n",
    "\n",
    "### Import√¢ncia\n",
    "\n",
    "A fun√ß√£o √© parte fundamental da **engenharia de atributos (feature engineering)** do pipeline de aprendizado de m√°quina, permitindo que o modelo LSTM receba n√£o apenas a s√©rie temporal bruta de pre√ßos, mas tamb√©m vari√°veis derivadas que capturam comportamento de tend√™ncia, momentum, revers√µes e press√µes de compra/venda.\n",
    "\n",
    "Estes indicadores enriquecem os dados com uma **representa√ß√£o multidimensional do contexto do pre√ßo**, melhorando a capacidade preditiva do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6090b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fun√ß√£o para adicionar indicadores t√©cnicos ---\n",
    "def add_technical_indicators(df):\n",
    "    if 'Close' not in df.columns:\n",
    "        raise ValueError(\"DataFrame n√£o cont√©m coluna 'Close'\")\n",
    "\n",
    "    try:\n",
    "        df['RSI'] = RSIIndicator(close=df['Close'], window=14).rsi()\n",
    "\n",
    "        stoch = StochasticOscillator(high=df['High'], low=df['Low'], close=df['Close'], window=14, smooth_window=3)\n",
    "        df['Stoch_K'] = stoch.stoch()\n",
    "        df['Stoch_D'] = stoch.stoch_signal()\n",
    "\n",
    "        ao = AwesomeOscillatorIndicator(high=df['High'], low=df['Low'], window1=5, window2=34)\n",
    "        df['Awesome_Oscillator'] = ao.awesome_oscillator()\n",
    "\n",
    "        macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "        df['MACD'] = macd.macd()\n",
    "        df['MACD_signal'] = macd.macd_signal()\n",
    "        df['MACD_diff'] = macd.macd_diff()\n",
    "\n",
    "\n",
    "        df['CCI'] = CCIIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=20).cci()\n",
    "\n",
    "        adx = ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=14)\n",
    "        df['ADX'] = adx.adx()\n",
    "        df['ADX_pos'] = adx.adx_pos()\n",
    "        df['ADX_neg'] = adx.adx_neg()\n",
    "\n",
    "        df['EMA_20'] = EMAIndicator(close=df['Close'], window=20).ema_indicator()\n",
    "\n",
    "        bb = BollingerBands(close=df['Close'], window=20, window_dev=2)\n",
    "        df['BB_upper'] = bb.bollinger_hband()\n",
    "        df['BB_middle'] = bb.bollinger_mavg()\n",
    "        df['BB_lower'] = bb.bollinger_lband()\n",
    "\n",
    "\n",
    "        df['ATR'] = AverageTrueRange(high=df['High'], low=df['Low'], close=df['Close'], window=14).average_true_range()\n",
    "\n",
    "        df['OBV'] = OnBalanceVolumeIndicator(close=df['Close'], volume=df['Volume']).on_balance_volume()\n",
    "        df['AccDistIndex'] = AccDistIndexIndicator(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume']).acc_dist_index()\n",
    "\n",
    "        if all(col in df.columns for col in ['High', 'Low', 'Close', 'Volume']):\n",
    "            df['VWAP'] = VolumeWeightedAveragePrice(\n",
    "                high=df['High'],\n",
    "                low=df['Low'],\n",
    "                close=df['Close'],\n",
    "                volume=df['Volume'],\n",
    "                window=14\n",
    "            ).volume_weighted_average_price()\n",
    "        else:\n",
    "            df['VWAP'] = np.nan\n",
    "\n",
    "        df['Candle_Body'] = df['Close'] - df['Open']\n",
    "        df['Candle_Range'] = df['High'] - df['Low']\n",
    "        df['Upper_Shadow'] = df['High'] - df[['Close', 'Open']].max(axis=1)\n",
    "        df['Lower_Shadow'] = df[['Close', 'Open']].min(axis=1) - df['Low']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular indicadores t√©cnicos: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1aaa29",
   "metadata": {},
   "source": [
    "Neste m√≥dulo, s√£o definidas duas fun√ß√µes essenciais para a constru√ß√£o e avalia√ß√£o de um modelo de aprendizado profundo do tipo LSTM Bidirecional, aplicado √† previs√£o de s√©ries temporais financeiras.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Fun√ß√£o: `create_sequences(data, seq_length)`\n",
    "\n",
    "Essa fun√ß√£o transforma os dados de entrada em **sequ√™ncias temporais**, conforme necess√°rio para o treinamento de modelos do tipo LSTM.\n",
    "\n",
    "#### **Par√¢metros:**\n",
    "- `data`: Matriz NumPy com os dados normalizados, geralmente incluindo v√°rios indicadores t√©cnicos.\n",
    "- `seq_length`: Quantidade de passos temporais considerados em cada sequ√™ncia (janela deslizante).\n",
    "\n",
    "#### **Retorno:**\n",
    "- `X`: Conjunto de entradas com forma `(n_amostras, seq_length, n_features)`.\n",
    "- `y`: Vetor de sa√≠das com o valor da vari√°vel alvo (geralmente o pre√ßo de fechamento) no instante seguinte √† sequ√™ncia.\n",
    "\n",
    "#### **L√≥gica:**\n",
    "Para cada posi√ß√£o `i` no tempo:\n",
    "- `X[i]` = subconjunto de `data` com `seq_length` linhas (passos temporais).\n",
    "- `y[i]` = valor da vari√°vel alvo na posi√ß√£o `i + seq_length`.\n",
    "\n",
    "Esse formato √© ideal para treinar modelos que aprendem padr√µes temporais.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Fun√ß√£o: `train_and_evaluate(...)`\n",
    "\n",
    "Essa fun√ß√£o encapsula todo o processo de constru√ß√£o, treinamento, valida√ß√£o e avalia√ß√£o do modelo preditivo.\n",
    "\n",
    "#### **Par√¢metros:**\n",
    "- `X_train`, `y_train`: Dados de treino.\n",
    "- `X_test`, `y_test`: Dados de teste.\n",
    "- `params`: Dicion√°rio de hiperpar√¢metros, incluindo:\n",
    "  - `'lstm_units_1'`, `'lstm_units_2'`: N√∫mero de unidades LSTM em cada camada.\n",
    "  - `'dropout'`: Taxa de dropout.\n",
    "  - `'learning_rate'`: Taxa de aprendizado.\n",
    "  - `'epochs'`: N√∫mero m√°ximo de √©pocas.\n",
    "  - `'batch_size'`: Tamanho do lote.\n",
    "  - `'seq_length'`: Tamanho das sequ√™ncias de entrada.\n",
    "  - `'scaler'`: Objeto scaler usado para normaliza√ß√£o.\n",
    "- `n_features`: N√∫mero de colunas (indicadores) por amostra.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Arquitetura do Modelo\n",
    "\n",
    "A fun√ß√£o monta uma **rede neural recorrente** com a seguinte estrutura:\n",
    "\n",
    "```text\n",
    "Entrada (shape: seq_length x n_features)\n",
    "‚Üì\n",
    "Camada LSTM bidirecional (1¬™)\n",
    "‚Üì\n",
    "Dropout\n",
    "‚Üì\n",
    "Camada LSTM bidirecional (2¬™)\n",
    "‚Üì\n",
    "Dropout\n",
    "‚Üì\n",
    "Camada Densa (1 unidade - sa√≠da cont√≠nua)\n",
    "```\n",
    "\n",
    "- **LSTM Bidirecional**: Permite que o modelo aprenda depend√™ncias temporais tanto do passado quanto do futuro da sequ√™ncia.\n",
    "- **Dropout**: Previne overfitting ao remover conex√µes aleatoriamente durante o treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Valida√ß√£o e Early Stopping\n",
    "\n",
    "- **Valida√ß√£o**: 10% (ou valor definido em `VALIDATION_SPLIT`) do conjunto de treino √© usado para valida√ß√£o durante o treinamento.\n",
    "- **EarlyStopping**: Interrompe o treinamento se a perda de valida√ß√£o n√£o melhorar ap√≥s 10 √©pocas consecutivas, evitando overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Invers√£o da Escala\n",
    "\n",
    "Como os dados s√£o normalizados antes do treino, a fun√ß√£o realiza a **invers√£o da normaliza√ß√£o** para interpretar os resultados em escala original:\n",
    "\n",
    "```python\n",
    "def inverse_transform(scaler, data):\n",
    "    dummy = np.zeros((len(data), n_features))\n",
    "    dummy[:, 0] = data.flatten()\n",
    "    return scaler.inverse_transform(dummy)[:, 0]\n",
    "```\n",
    "\n",
    "A invers√£o √© feita apenas para a **primeira coluna**, que representa o valor de `Close`.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Avalia√ß√£o Final\n",
    "\n",
    "A fun√ß√£o retorna:\n",
    "\n",
    "- `rmse`: Erro quadr√°tico m√©dio da previs√£o (em escala original).\n",
    "- `mae`: Erro absoluto m√©dio da previs√£o.\n",
    "- `history`: Hist√≥rico do treinamento (valores de perda por √©poca).\n",
    "- `model`: Modelo treinado (objeto Keras).\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Observa√ß√£o\n",
    "\n",
    "Essas fun√ß√µes foram projetadas para integrar um pipeline de aprendizado profundo aplicado inicialmente aos dados da **a√ß√£o da VALE (VALE3.SA)**, como uma **prova de conceito (PoC)**. Ap√≥s valida√ß√£o do desempenho, o mesmo modelo poder√° ser generalizado para outras a√ß√µes ou ativos financeiros, com base na robustez dos indicadores t√©cnicos e da modelagem sequencial temporal.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936aa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fun√ß√£o para criar sequ√™ncias ---\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        X.append(data[i:(i + seq_length), :])\n",
    "        y.append(data[i + seq_length, 0])  # Close price na posi√ß√£o 0\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- Fun√ß√£o para treinar e avaliar o modelo ---\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, params, n_features):  \n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(params['lstm_units_1'], return_sequences=True), input_shape=(params['seq_length'], n_features)),\n",
    "        Dropout(params['dropout']),\n",
    "        Bidirectional(LSTM(params['lstm_units_2'])),\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Fun√ß√£o para inverter escala\n",
    "    def inverse_transform(scaler, data):\n",
    "        dummy = np.zeros((len(data), n_features))\n",
    "        dummy[:, 0] = data.flatten()\n",
    "        return scaler.inverse_transform(dummy)[:, 0]\n",
    "    \n",
    "    y_test_inv = inverse_transform(params['scaler'], y_test)\n",
    "    test_pred_inv = inverse_transform(params['scaler'], test_pred)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inv, test_pred_inv))\n",
    "    mae = mean_absolute_error(y_test_inv, test_pred_inv)\n",
    "    \n",
    "    return rmse, mae, history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248857d6",
   "metadata": {},
   "source": [
    "\n",
    "Este trecho de c√≥digo √© respons√°vel por coletar os dados hist√≥ricos da a√ß√£o, enriquecer com indicadores t√©cnicos e preparar os dados em formato adequado para o treinamento de um modelo de aprendizado profundo.\n",
    "\n",
    "---\n",
    "\n",
    "### üì• Coleta de Dados com o `yfinance`\n",
    "\n",
    "```python\n",
    "df = yf.download(symbol, period=period, interval=interval, progress=True)\n",
    "df.columns = df.columns.droplevel(1)\n",
    "```\n",
    "\n",
    "- Utiliza a biblioteca `yfinance` para baixar dados hist√≥ricos de pre√ßos do ativo definido pela vari√°vel `symbol`.\n",
    "- `period` define o intervalo temporal (ex: `\"2y\"`).\n",
    "- `interval` define a granularidade (ex: `\"1d\"`, `\"1h\"`).\n",
    "- Algumas vezes os dados retornam com MultiIndex; `droplevel(1)` limpa isso.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Enriquecimento com Indicadores T√©cnicos\n",
    "\n",
    "```python\n",
    "df = add_technical_indicators(df)\n",
    "df.dropna(inplace=True)\n",
    "```\n",
    "\n",
    "- A fun√ß√£o `add_technical_indicators(df)` insere colunas com indicadores de momentum, tend√™ncia, volatilidade, volume e padr√µes de candle.\n",
    "- Ap√≥s o c√°lculo dos indicadores, valores iniciais podem conter `NaN` devido √†s janelas m√≥veis ‚Üí s√£o removidos com `dropna`.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Sele√ß√£o das Features\n",
    "\n",
    "```python\n",
    "available_features = [ ... ]\n",
    "features = [f for f in available_features if f in df.columns]\n",
    "df = df[features]\n",
    "```\n",
    "\n",
    "- Define um conjunto completo de **vari√°veis de entrada candidatas** (features) para o modelo.\n",
    "- Utiliza uma verifica√ß√£o para garantir que apenas as colunas calculadas de fato (que existem em `df`) sejam usadas.\n",
    "- Garante consist√™ncia e evita erros caso alguma feature falhe durante o c√°lculo.\n",
    "\n",
    "#### As features selecionadas incluem:\n",
    "- **Pre√ßos e volume b√°sicos**: `Open`, `High`, `Low`, `Close`, `Volume`.\n",
    "- **Indicadores t√©cnicos de momentum**: `RSI`, `Stoch_K`, `Stoch_D`, `Awesome_Oscillator`.\n",
    "- **MACD e seus componentes**: `MACD`, `MACD_signal`, `MACD_diff`.\n",
    "- **Indicadores de tend√™ncia**: `CCI`, `ADX`, `ADX_pos`, `ADX_neg`.\n",
    "- **Bandas de Bollinger**: `BB_upper`, `BB_middle`, `BB_lower`.\n",
    "- **M√©dia m√≥vel**: `EMA_20`.\n",
    "- **Volatilidade**: `ATR`.\n",
    "- **Volume inteligente**: `VWAP`, `OBV`, `AccDistIndex`.\n",
    "- **Padr√µes de candle**: `Candle_Body`, `Candle_Range`, `Upper_Shadow`, `Lower_Shadow`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÇÔ∏è Divis√£o Treino/Teste com Normaliza√ß√£o\n",
    "\n",
    "```python\n",
    "def prepare_data(df, seq_length=SEQ_LENGTH_DEFAULT):\n",
    "    num_samples = len(df) - seq_length - 1\n",
    "    train_size = int(num_samples * (1 - TEST_SIZE))\n",
    "    \n",
    "    df_train = df.iloc[:train_size + seq_length + 1].copy()\n",
    "    df_test = df.iloc[train_size:].copy()\n",
    "```\n",
    "\n",
    "- Define a propor√ß√£o de treino/teste com base na constante `TEST_SIZE` (ex: 0.2).\n",
    "- Garante que tanto o conjunto de treino quanto o de teste contenham sequ√™ncias completas (`+ seq_length + 1`).\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Normaliza√ß√£o com `MinMaxScaler`\n",
    "\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train)\n",
    "train_scaled = scaler.transform(df_train)\n",
    "test_scaled = scaler.transform(df_test)\n",
    "```\n",
    "\n",
    "- Aplica a **normaliza√ß√£o MinMax** nos dados, transformando os valores para a faixa `[0, 1]`.\n",
    "- **Importante**: o scaler √© treinado **apenas com dados de treino**, para evitar vazamento de informa√ß√£o (`data leakage`).\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Cria√ß√£o das Sequ√™ncias Temporais\n",
    "\n",
    "```python\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "```\n",
    "\n",
    "- Gera os conjuntos de entrada (`X`) e sa√≠da (`y`) para o modelo, com base nas janelas de `seq_length` per√≠odos.\n",
    "\n",
    "---\n",
    "\n",
    "### üîö Retorno da Fun√ß√£o\n",
    "\n",
    "```python\n",
    "return X_train, y_train, X_test, y_test, scaler\n",
    "```\n",
    "\n",
    "- A fun√ß√£o retorna os dados processados e prontos para o treinamento, al√©m do `scaler`, que ser√° necess√°rio para inverter a normaliza√ß√£o ap√≥s a predi√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Contexto da Prova de Conceito (PoC)\n",
    "\n",
    "Este pipeline de prepara√ß√£o de dados foi desenvolvido no contexto de uma **prova de conceito (PoC)** uti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(symbol, period=period, interval=interval, progress=True)\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "df = add_technical_indicators(df)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "available_features = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',             # Pre√ßos e volume b√°sicos\n",
    "    'RSI', 'Stoch_K', 'Stoch_D', 'Awesome_Oscillator',    # Indicadores de momentum\n",
    "    'MACD', 'MACD_signal', 'MACD_diff',                   # MACD\n",
    "    'CCI', 'ADX', 'ADX_pos', 'ADX_neg',                   # Indicadores de tend√™ncia\n",
    "    'BB_upper', 'BB_middle', 'BB_lower',                  # Bandas de Bollinger\n",
    "    'EMA_20',                                             # M√©dia m√≥vel exponencial\n",
    "    'ATR',                                                # Volatilidade\n",
    "    'VWAP', 'OBV', 'AccDistIndex',                        # Indicadores de volume\n",
    "    'Candle_Body', 'Candle_Range', 'Upper_Shadow', 'Lower_Shadow'  # Candlestick features\n",
    "]\n",
    "\n",
    "features = [f for f in available_features if f in df.columns]\n",
    "print(\"Features selecionadas:\", features)\n",
    "\n",
    "df = df[features]\n",
    "\n",
    "# --- Divis√£o treino/teste ---\n",
    "def prepare_data(df, seq_length=SEQ_LENGTH_DEFAULT):\n",
    "    num_samples = len(df) - seq_length - 1\n",
    "    train_size = int(num_samples * (1 - TEST_SIZE))\n",
    "    df_train = df.iloc[:train_size + seq_length + 1].copy()\n",
    "    df_test = df.iloc[train_size:].copy()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train)\n",
    "    train_scaled = scaler.transform(df_train)\n",
    "    test_scaled = scaler.transform(df_test)\n",
    "    \n",
    "    X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "    X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8731495",
   "metadata": {},
   "source": [
    "## üîß Busca Randomizada de Hiperpar√¢metros para Modelos LSTM\n",
    "\n",
    "Este bloco de c√≥digo realiza uma **busca aleat√≥ria (random search)** para encontrar a melhor combina√ß√£o de hiperpar√¢metros de um modelo LSTM bidirecional, visando minimizar o erro RMSE (Root Mean Squared Error) na previs√£o de pre√ßos de ativos financeiros.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objetivo da Otimiza√ß√£o\n",
    "\n",
    "Selecionar, entre diferentes combina√ß√µes de hiperpar√¢metros, aquela que oferece o melhor desempenho em termos de RMSE sobre o conjunto de teste. O processo explora o espa√ßo de configura√ß√µes e compara os resultados, armazenando o melhor modelo encontrado.\n",
    "\n",
    "---\n",
    "\n",
    "### üß∞ Defini√ß√£o do Espa√ßo de Busca\n",
    "\n",
    "```python\n",
    "search_space = {\n",
    "    'seq_length': [12, 24, 36, 48, 60],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'epochs': [50, 80, 100, 120, 150],\n",
    "    'lstm_units_1': [64, 128, 256, 384, 512],\n",
    "    'lstm_units_2': [32, 64, 128, 192, 256],\n",
    "    'dropout': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005]  \n",
    "}\n",
    "```\n",
    "\n",
    "- Define os valores poss√≠veis para cada hiperpar√¢metro.\n",
    "- **`seq_length`**: N√∫mero de observa√ß√µes anteriores usadas como entrada.\n",
    "- **`batch_size`**: Quantidade de amostras processadas por itera√ß√£o.\n",
    "- **`epochs`**: N√∫mero m√°ximo de ciclos de treinamento.\n",
    "- **`lstm_units_1`/`lstm_units_2`**: N√∫mero de neur√¥nios nas camadas LSTM bidirecionais.\n",
    "- **`dropout`**: Fra√ß√£o de unidades descartadas durante o treinamento para evitar overfitting.\n",
    "- **`learning_rate`**: Taxa de aprendizado usada pelo otimizador `Adam`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Processo de Busca Aleat√≥ria\n",
    "\n",
    "```python\n",
    "n_trials = 10\n",
    "best_rmse = float('inf')\n",
    "```\n",
    "\n",
    "- Define `n_trials` como o n√∫mero total de execu√ß√µes (combina√ß√µes aleat√≥rias a serem testadas).\n",
    "- Inicializa a vari√°vel `best_rmse` como infinito, para garantir que qualquer RMSE v√°lido ser√° menor.\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Loop de Execu√ß√µes\n",
    "\n",
    "```python\n",
    "for trial in range(n_trials):\n",
    "    params = {\n",
    "        'seq_length': random.choice(...),\n",
    "        ...\n",
    "    }\n",
    "```\n",
    "\n",
    "- Para cada tentativa:\n",
    "  - Seleciona **aleatoriamente** um valor para cada hiperpar√¢metro a partir do `search_space`.\n",
    "  - Armazena os valores selecionados no dicion√°rio `params`.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Prepara√ß√£o de Dados com `prepare_data`\n",
    "\n",
    "```python\n",
    "X_train, y_train, X_test, y_test, scaler = prepare_data(df, seq_length=params['seq_length'])\n",
    "params['scaler'] = scaler\n",
    "```\n",
    "\n",
    "- Os dados s√£o normalizados e divididos com base no `seq_length` escolhido.\n",
    "- O `scaler` √© salvo dentro de `params` para permitir a invers√£o da escala posteriormente.\n",
    "\n",
    "---\n",
    "\n",
    "### üèãÔ∏è‚Äç‚ôÇÔ∏è Treinamento e Avalia√ß√£o\n",
    "\n",
    "```python\n",
    "rmse, mae, history, model = train_and_evaluate(...)\n",
    "```\n",
    "\n",
    "- Treina o modelo LSTM com os hiperpar√¢metros atuais.\n",
    "- Avalia seu desempenho utilizando m√©tricas padronizadas:\n",
    "  - **RMSE (Root Mean Squared Error)**: penaliza erros maiores.\n",
    "  - **MAE (Mean Absolute Error)**: m√©dia dos erros absolutos.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Atualiza√ß√£o do Melhor Modelo\n",
    "\n",
    "```python\n",
    "if rmse < best_rmse:\n",
    "    best_rmse = rmse\n",
    "    best_params = params\n",
    "    best_model = model\n",
    "    best_history = history\n",
    "```\n",
    "\n",
    "- Se o modelo atual tiver desempenho superior ao melhor at√© ent√£o:\n",
    "  - Salva os hiperpar√¢metros, o modelo treinado e o hist√≥rico de treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ Registro dos Resultados\n",
    "\n",
    "```python\n",
    "results.append({\n",
    "    'trial': trial + 1,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    **params\n",
    "})\n",
    "```\n",
    "\n",
    "- Armazena todas as m√©tricas e os hiperpar√¢metros testados para posterior an√°lise.\n",
    "\n",
    "---\n",
    "\n",
    "### üèÅ Resultados Finais\n",
    "\n",
    "```python\n",
    "print(\"\\nMelhor RMSE:\", best_rmse)\n",
    "print(\"Melhores hiperpar√¢metros:\", best_params)\n",
    "```\n",
    "\n",
    "- Exibe a melhor configura√ß√£o encontrada ap√≥s todos os testes realizados.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Considera√ß√µes T√©cnicas\n",
    "\n",
    "- **Random Search** √© menos eficiente que m√©todos baseados em gradiente ou Bayesian Optimization, mas √∫til em contextos onde:\n",
    "  - O custo de cada avalia√ß√£o √© alto.\n",
    "  - O espa√ßo de busca √© n√£o cont√≠nuo.\n",
    "  - A fun√ß√£o objetivo (modelo) √© n√£o diferenci√°vel.\n",
    "\n",
    "- A randomiza√ß√£o evita vi√©s e permite cobrir melhor o espa√ßo de busca do que uma simples busca em grade (grid search) quando o n√∫mero de tentativas √© limitado.\n",
    "\n",
    "- Este m√©todo √© especialmente adequado para provas de conceito (PoC) e cen√°rios com restri√ß√µes de tempo computacional.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Relev√¢ncia para S√©ries Temporais\n",
    "\n",
    "Em modelos baseados em LSTM para s√©ries temporais:\n",
    "- Pequenas varia√ß√µes em `seq_length`, `lstm_units` ou `learning_rate` podem ter impacto significativo na capacidade do modelo de **capturar padr√µes de longo prazo**.\n",
    "- O uso de `Dropout` ajuda a combater o overfitting, comum quando h√° correla√ß√£o temporal elevada entre amostras adjacentes.\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ Pr√≥ximos Passos\n",
    "\n",
    "- Persistir os melhores resultados (par√¢metros, m√©tricas, modelo).\n",
    "- Visualizar o `history` de treinamento (loss x epochs).\n",
    "- Avaliar generaliza√ß√£o para novos dados (valida√ß√£o out-of-sample).\n",
    "- Implementar uma busca **Bayesiana** com `Optuna` ou `KerasTuner` para refinamento posterior.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55248a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Espa√ßo de hiperpar√¢metros para busca ---\n",
    "search_space = {\n",
    "    'seq_length': [12, 24, 36, 48, 60],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'epochs': [50, 80, 100, 120, 150],\n",
    "    'lstm_units_1': [64, 128, 256, 384, 512],\n",
    "    'lstm_units_2': [32, 64, 128, 192, 256],\n",
    "    'dropout': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005]  \n",
    "}\n",
    "\n",
    "# --- Busca randomizada ---\n",
    "n_trials = 10  # quantas combina√ß√µes testar\n",
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "best_model = None\n",
    "best_history = None\n",
    "results = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    params = {\n",
    "        'seq_length': random.choice(search_space['seq_length']),\n",
    "        'batch_size': random.choice(search_space['batch_size']),\n",
    "        'epochs': random.choice(search_space['epochs']),\n",
    "        'lstm_units_1': random.choice(search_space['lstm_units_1']),\n",
    "        'lstm_units_2': random.choice(search_space['lstm_units_2']),\n",
    "        'dropout': random.choice(search_space['dropout']),\n",
    "        'learning_rate': random.choice(search_space['learning_rate']),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTrial {trial+1}/{n_trials} com params: {params}\")\n",
    "    \n",
    "    # Preparar dados para o seq_length atual\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_data(df, seq_length=params['seq_length'])\n",
    "    params['scaler'] = scaler\n",
    "    \n",
    "    # Treinar e avaliar\n",
    "    try:\n",
    "        rmse, mae, history, model = train_and_evaluate(X_train, y_train, X_test, y_test, params, n_features=len(features))\n",
    "        print(f\"RMSE: {rmse:.4f} - MAE: {mae:.4f}\")\n",
    "        \n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            best_history = history\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no treino/avalia√ß√£o: {e}\")\n",
    "        \n",
    "results.append({\n",
    "    'trial': trial + 1,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    **params  # isso inclui todos os hiperpar√¢metros testados\n",
    "})\n",
    "\n",
    "print(\"\\nMelhor RMSE:\", best_rmse)\n",
    "print(\"Melhores hiperpar√¢metros:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092c328",
   "metadata": {},
   "source": [
    "| O c√≥digo plota um gr√°fico que compara os pre√ßos reais de fechamento com as previs√µes feitas pelo melhor modelo treinado. Para isso, ele primeiro reverte a escala dos dados normalizados para valores reais, tanto para os dados de teste quanto para as previs√µes, utilizando o mesmo scaler. Em seguida, exibe essa compara√ß√£o visualmente, permitindo avaliar a precis√£o do modelo na previs√£o dos pre√ßos ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotar resultado com melhor modelo ---\n",
    "if best_model:\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_data(df, seq_length=best_params['seq_length'])\n",
    "    y_test_inv = scaler.inverse_transform(\n",
    "        np.concatenate([y_test.reshape(-1,1), np.zeros((len(y_test), len(features)-1))], axis=1)\n",
    "    )[:, 0]\n",
    "    \n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_pred_inv = scaler.inverse_transform(\n",
    "        np.concatenate([test_pred, np.zeros((len(test_pred), len(features)-1))], axis=1)\n",
    "    )[:, 0]\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(y_test_inv, label='Valor Real')\n",
    "    plt.plot(test_pred_inv, label='Previs√£o')\n",
    "    plt.title(f'Previs√£o do Pre√ßo de Fechamento - {symbol} (Melhor Modelo)')\n",
    "    plt.xlabel('Horas')\n",
    "    plt.ylabel('Pre√ßo (R$)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90174264",
   "metadata": {},
   "source": [
    "| Ap√≥s o treinamento do modelo e a obten√ß√£o dos melhores resultados, √© fundamental salvar o modelo para que ele possa ser reutilizado posteriormente sem a necessidade de ser re-treinado. O formato .h5 √© amplamente utilizado em projetos que envolvem modelos Keras/TensorFlow, pois permite armazenar tanto a arquitetura quanto os pesos do modelo em um √∫nico arquivo. Isso facilita a implanta√ß√£o, compartilhamento e posterior an√°lise do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o melhor modelo em formato HDF5 (.h5)\n",
    "if best_model:\n",
    "    best_model.save('../model/modelo_v1.h5')\n",
    "    print(\"Modelo salvo com sucesso no arquivo 'best_lstm_model.h5'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
