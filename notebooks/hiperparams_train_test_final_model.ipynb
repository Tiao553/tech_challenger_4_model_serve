{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7d24a1",
   "metadata": {},
   "source": [
    "## Introdução à Metodologia de Previsão de Preço com LSTM e Indicadores Técnicos\n",
    "\n",
    "Este código implementa uma metodologia moderna para previsão de preços de ações no curtíssimo prazo (intradia), utilizando redes neurais recorrentes (LSTM bidirecionais) em conjunto com uma ampla gama de indicadores técnicos clássicos. A abordagem combina princípios tradicionais da análise técnica com técnicas contemporâneas de aprendizado profundo.\n",
    "\n",
    "> **Importante**: Esta implementação está sendo aplicada inicialmente à ação `VALE3.SA`, da mineradora Vale, como uma **prova de conceito (PoC)**. A escolha se deve à sua alta liquidez e relevância no mercado brasileiro. A intenção é, após validação da abordagem com esta ação, **escalar a metodologia para outras ações da bolsa** que apresentem perfil semelhante ou apresentem interesse estratégico.\n",
    "\n",
    "A seguir, descrevemos os principais componentes da metodologia:\n",
    "\n",
    "### 1. **Aquisição de Dados**\n",
    "Utiliza-se a biblioteca `yfinance` para coletar dados intradiários (com granularidade de 1 minuto) da ação `VALE3.SA` por um período de 7 dias. Os dados incluem colunas como `Open`, `High`, `Low`, `Close` e `Volume`.\n",
    "\n",
    "### 2. **Engenharia de Atributos Técnicos**\n",
    "A função `add_technical_indicators` incorpora uma rica variedade de indicadores técnicos ao conjunto de dados, dentre os quais se destacam:\n",
    "\n",
    "- **Indicadores de momentum**: RSI, Estocástico, Oscilador Awesome.\n",
    "- **Indicadores de tendência**: MACD, ADX, CCI, Média Móvel Exponencial.\n",
    "- **Indicadores de volatilidade**: Bandas de Bollinger, ATR.\n",
    "- **Indicadores de volume**: OBV, VWAP, Índice de Acumulação/Distribuição.\n",
    "- **Características de candlestick**: corpo, sombras e amplitude do candle.\n",
    "\n",
    "Esses atributos auxiliam o modelo a captar padrões não triviais no comportamento dos preços.\n",
    "\n",
    "### 3. **Normalização e Sequenciamento**\n",
    "Os dados são normalizados com `MinMaxScaler` e, em seguida, organizados em sequências temporais (janelas deslizantes) com tamanho variável (ex. 24, 36, 60 minutos), de modo a alimentar a rede neural com informações históricas para prever o próximo valor de fechamento.\n",
    "\n",
    "### 4. **Estrutura do Modelo**\n",
    "O modelo preditivo é uma rede neural do tipo **Bidirectional LSTM**, composta por duas camadas LSTM (com possibilidade de dropout), seguida de uma camada densa para saída única (preço futuro). A bidirecionalidade permite à rede capturar relações tanto no sentido passado → futuro quanto futuro → passado.\n",
    "\n",
    "### 5. **Treinamento e Avaliação**\n",
    "O modelo é treinado com validação cruzada (via `validation_split`) e parada antecipada (`EarlyStopping`). Para cada combinação de hiperparâmetros, calcula-se o erro médio absoluto (MAE) e o erro quadrático médio da raiz (RMSE) com base em dados de teste.\n",
    "\n",
    "### 6. **Otimização de Hiperparâmetros**\n",
    "A busca por melhores combinações de hiperparâmetros é feita através de uma busca randomizada, onde múltiplas configurações são testadas automaticamente, e os resultados são registrados para identificação do melhor desempenho.\n",
    "\n",
    "### 7. **Visualização dos Resultados**\n",
    "Após o melhor modelo ser identificado, suas previsões são desnormalizadas e comparadas graficamente com os valores reais. O gráfico resultante mostra visualmente a capacidade preditiva do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "Essa metodologia visa conciliar o conhecimento consagrado dos mercados financeiros (análise técnica) com as potencialidades do aprendizado de máquina sequencial, oferecendo uma base robusta para previsões em cenários de alta frequência e curto prazo.\n",
    "\n",
    "O uso inicial da ação VALE3 permite validar a robustez da abordagem com um ativo de grande liquidez. Uma vez confirmada a eficácia, a arquitetura será reaproveitada e ajustada para outras ações brasileiras, com foco na escalabilidade e reprodutibilidade do pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391512b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD, EMAIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.volume import VolumeWeightedAveragePrice\n",
    "from ta.momentum import StochasticOscillator, AwesomeOscillatorIndicator\n",
    "from ta.volume import VolumeWeightedAveragePrice, OnBalanceVolumeIndicator, AccDistIndexIndicator\n",
    "from ta.trend import CCIIndicator, ADXIndicator, EMAIndicator\n",
    "from ta.volatility import AverageTrueRange\n",
    "import random\n",
    "\n",
    "# --- Parâmetros fixos ---\n",
    "\n",
    "symbol = 'VALE3.SA'\n",
    "period = '7d'\n",
    "interval = '1m'\n",
    "SEQ_LENGTH_DEFAULT = 24\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe4f2e",
   "metadata": {},
   "source": [
    "A função `add_technical_indicators` é responsável por enriquecer um `DataFrame` de preços de ações com uma ampla variedade de **indicadores técnicos clássicos**, comumente utilizados em análise técnica para tomada de decisão no mercado financeiro.\n",
    "\n",
    "Essa função assume que o `DataFrame` de entrada (`df`) contém, pelo menos, as colunas: `Open`, `High`, `Low`, `Close`, e `Volume`.\n",
    "\n",
    "### Visão Geral\n",
    "\n",
    "- **Objetivo:** Adicionar colunas com indicadores técnicos calculados a partir dos preços históricos da ação.\n",
    "- **Pré-condição:** A coluna `'Close'` deve existir no `DataFrame`. Caso contrário, uma exceção será lançada.\n",
    "- **Tratamento de Erros:** Qualquer falha no cálculo dos indicadores resulta em uma exceção com mensagem detalhada.\n",
    "\n",
    "---\n",
    "\n",
    "### Indicadores Adicionados\n",
    "\n",
    "Abaixo, listam-se os indicadores incluídos e seu propósito:\n",
    "\n",
    "#### 1. **Indicadores de Momentum**\n",
    "\n",
    "- `RSI`: Índice de Força Relativa com janela de 14 períodos.\n",
    "- `Stoch_K` e `Stoch_D`: Oscilador Estocástico %K e sua média móvel %D.\n",
    "- `Awesome_Oscillator`: Mede a força do momentum com duas médias móveis simples (5 e 34).\n",
    "\n",
    "#### 2. **Indicadores de Tendência**\n",
    "\n",
    "- `MACD`, `MACD_signal`, `MACD_diff`: Conjunto completo de MACD (12, 26, 9), incluindo linha de sinal e histograma.\n",
    "- `CCI`: Commodity Channel Index com janela de 20 períodos.\n",
    "- `ADX`, `ADX_pos`, `ADX_neg`: Índice Direcional Médio (ADX), e componentes positivo e negativo, com janela de 14 períodos.\n",
    "- `EMA_20`: Média móvel exponencial de 20 períodos.\n",
    "\n",
    "#### 3. **Indicadores de Volatilidade**\n",
    "\n",
    "- `BB_upper`, `BB_middle`, `BB_lower`: Bandas de Bollinger (20 períodos, 2 desvios padrão).\n",
    "- `ATR`: True Range Médio (Average True Range) com janela de 14 períodos.\n",
    "\n",
    "#### 4. **Indicadores de Volume**\n",
    "\n",
    "- `OBV`: On-Balance Volume.\n",
    "- `AccDistIndex`: Índice de Acumulação/Distribuição.\n",
    "- `VWAP`: Preço médio ponderado por volume, com janela de 14 períodos (calculado somente se todas as colunas requeridas estiverem presentes).\n",
    "\n",
    "#### 5. **Características do Candle**\n",
    "\n",
    "- `Candle_Body`: Corpo do candle (Close - Open).\n",
    "- `Candle_Range`: Amplitude do candle (High - Low).\n",
    "- `Upper_Shadow`: Sombra superior (High - max(Open, Close)).\n",
    "- `Lower_Shadow`: Sombra inferior (min(Open, Close) - Low).\n",
    "\n",
    "---\n",
    "\n",
    "### Importância\n",
    "\n",
    "A função é parte fundamental da **engenharia de atributos (feature engineering)** do pipeline de aprendizado de máquina, permitindo que o modelo LSTM receba não apenas a série temporal bruta de preços, mas também variáveis derivadas que capturam comportamento de tendência, momentum, reversões e pressões de compra/venda.\n",
    "\n",
    "Estes indicadores enriquecem os dados com uma **representação multidimensional do contexto do preço**, melhorando a capacidade preditiva do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6090b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Função para adicionar indicadores técnicos ---\n",
    "def add_technical_indicators(df):\n",
    "    if 'Close' not in df.columns:\n",
    "        raise ValueError(\"DataFrame não contém coluna 'Close'\")\n",
    "\n",
    "    try:\n",
    "        df['RSI'] = RSIIndicator(close=df['Close'], window=14).rsi()\n",
    "\n",
    "        stoch = StochasticOscillator(high=df['High'], low=df['Low'], close=df['Close'], window=14, smooth_window=3)\n",
    "        df['Stoch_K'] = stoch.stoch()\n",
    "        df['Stoch_D'] = stoch.stoch_signal()\n",
    "\n",
    "        ao = AwesomeOscillatorIndicator(high=df['High'], low=df['Low'], window1=5, window2=34)\n",
    "        df['Awesome_Oscillator'] = ao.awesome_oscillator()\n",
    "\n",
    "        macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "        df['MACD'] = macd.macd()\n",
    "        df['MACD_signal'] = macd.macd_signal()\n",
    "        df['MACD_diff'] = macd.macd_diff()\n",
    "\n",
    "\n",
    "        df['CCI'] = CCIIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=20).cci()\n",
    "\n",
    "        adx = ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=14)\n",
    "        df['ADX'] = adx.adx()\n",
    "        df['ADX_pos'] = adx.adx_pos()\n",
    "        df['ADX_neg'] = adx.adx_neg()\n",
    "\n",
    "        df['EMA_20'] = EMAIndicator(close=df['Close'], window=20).ema_indicator()\n",
    "\n",
    "        bb = BollingerBands(close=df['Close'], window=20, window_dev=2)\n",
    "        df['BB_upper'] = bb.bollinger_hband()\n",
    "        df['BB_middle'] = bb.bollinger_mavg()\n",
    "        df['BB_lower'] = bb.bollinger_lband()\n",
    "\n",
    "\n",
    "        df['ATR'] = AverageTrueRange(high=df['High'], low=df['Low'], close=df['Close'], window=14).average_true_range()\n",
    "\n",
    "        df['OBV'] = OnBalanceVolumeIndicator(close=df['Close'], volume=df['Volume']).on_balance_volume()\n",
    "        df['AccDistIndex'] = AccDistIndexIndicator(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume']).acc_dist_index()\n",
    "\n",
    "        if all(col in df.columns for col in ['High', 'Low', 'Close', 'Volume']):\n",
    "            df['VWAP'] = VolumeWeightedAveragePrice(\n",
    "                high=df['High'],\n",
    "                low=df['Low'],\n",
    "                close=df['Close'],\n",
    "                volume=df['Volume'],\n",
    "                window=14\n",
    "            ).volume_weighted_average_price()\n",
    "        else:\n",
    "            df['VWAP'] = np.nan\n",
    "\n",
    "        df['Candle_Body'] = df['Close'] - df['Open']\n",
    "        df['Candle_Range'] = df['High'] - df['Low']\n",
    "        df['Upper_Shadow'] = df['High'] - df[['Close', 'Open']].max(axis=1)\n",
    "        df['Lower_Shadow'] = df[['Close', 'Open']].min(axis=1) - df['Low']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular indicadores técnicos: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1aaa29",
   "metadata": {},
   "source": [
    "Neste módulo, são definidas duas funções essenciais para a construção e avaliação de um modelo de aprendizado profundo do tipo LSTM Bidirecional, aplicado à previsão de séries temporais financeiras.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Função: `create_sequences(data, seq_length)`\n",
    "\n",
    "Essa função transforma os dados de entrada em **sequências temporais**, conforme necessário para o treinamento de modelos do tipo LSTM.\n",
    "\n",
    "#### **Parâmetros:**\n",
    "- `data`: Matriz NumPy com os dados normalizados, geralmente incluindo vários indicadores técnicos.\n",
    "- `seq_length`: Quantidade de passos temporais considerados em cada sequência (janela deslizante).\n",
    "\n",
    "#### **Retorno:**\n",
    "- `X`: Conjunto de entradas com forma `(n_amostras, seq_length, n_features)`.\n",
    "- `y`: Vetor de saídas com o valor da variável alvo (geralmente o preço de fechamento) no instante seguinte à sequência.\n",
    "\n",
    "#### **Lógica:**\n",
    "Para cada posição `i` no tempo:\n",
    "- `X[i]` = subconjunto de `data` com `seq_length` linhas (passos temporais).\n",
    "- `y[i]` = valor da variável alvo na posição `i + seq_length`.\n",
    "\n",
    "Esse formato é ideal para treinar modelos que aprendem padrões temporais.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Função: `train_and_evaluate(...)`\n",
    "\n",
    "Essa função encapsula todo o processo de construção, treinamento, validação e avaliação do modelo preditivo.\n",
    "\n",
    "#### **Parâmetros:**\n",
    "- `X_train`, `y_train`: Dados de treino.\n",
    "- `X_test`, `y_test`: Dados de teste.\n",
    "- `params`: Dicionário de hiperparâmetros, incluindo:\n",
    "  - `'lstm_units_1'`, `'lstm_units_2'`: Número de unidades LSTM em cada camada.\n",
    "  - `'dropout'`: Taxa de dropout.\n",
    "  - `'learning_rate'`: Taxa de aprendizado.\n",
    "  - `'epochs'`: Número máximo de épocas.\n",
    "  - `'batch_size'`: Tamanho do lote.\n",
    "  - `'seq_length'`: Tamanho das sequências de entrada.\n",
    "  - `'scaler'`: Objeto scaler usado para normalização.\n",
    "- `n_features`: Número de colunas (indicadores) por amostra.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 Arquitetura do Modelo\n",
    "\n",
    "A função monta uma **rede neural recorrente** com a seguinte estrutura:\n",
    "\n",
    "```text\n",
    "Entrada (shape: seq_length x n_features)\n",
    "↓\n",
    "Camada LSTM bidirecional (1ª)\n",
    "↓\n",
    "Dropout\n",
    "↓\n",
    "Camada LSTM bidirecional (2ª)\n",
    "↓\n",
    "Dropout\n",
    "↓\n",
    "Camada Densa (1 unidade - saída contínua)\n",
    "```\n",
    "\n",
    "- **LSTM Bidirecional**: Permite que o modelo aprenda dependências temporais tanto do passado quanto do futuro da sequência.\n",
    "- **Dropout**: Previne overfitting ao remover conexões aleatoriamente durante o treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Validação e Early Stopping\n",
    "\n",
    "- **Validação**: 10% (ou valor definido em `VALIDATION_SPLIT`) do conjunto de treino é usado para validação durante o treinamento.\n",
    "- **EarlyStopping**: Interrompe o treinamento se a perda de validação não melhorar após 10 épocas consecutivas, evitando overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 Inversão da Escala\n",
    "\n",
    "Como os dados são normalizados antes do treino, a função realiza a **inversão da normalização** para interpretar os resultados em escala original:\n",
    "\n",
    "```python\n",
    "def inverse_transform(scaler, data):\n",
    "    dummy = np.zeros((len(data), n_features))\n",
    "    dummy[:, 0] = data.flatten()\n",
    "    return scaler.inverse_transform(dummy)[:, 0]\n",
    "```\n",
    "\n",
    "A inversão é feita apenas para a **primeira coluna**, que representa o valor de `Close`.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Avaliação Final\n",
    "\n",
    "A função retorna:\n",
    "\n",
    "- `rmse`: Erro quadrático médio da previsão (em escala original).\n",
    "- `mae`: Erro absoluto médio da previsão.\n",
    "- `history`: Histórico do treinamento (valores de perda por época).\n",
    "- `model`: Modelo treinado (objeto Keras).\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Observação\n",
    "\n",
    "Essas funções foram projetadas para integrar um pipeline de aprendizado profundo aplicado inicialmente aos dados da **ação da VALE (VALE3.SA)**, como uma **prova de conceito (PoC)**. Após validação do desempenho, o mesmo modelo poderá ser generalizado para outras ações ou ativos financeiros, com base na robustez dos indicadores técnicos e da modelagem sequencial temporal.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936aa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Função para criar sequências ---\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        X.append(data[i:(i + seq_length), :])\n",
    "        y.append(data[i + seq_length, 0])  # Close price na posição 0\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- Função para treinar e avaliar o modelo ---\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, params, n_features):  \n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(params['lstm_units_1'], return_sequences=True), input_shape=(params['seq_length'], n_features)),\n",
    "        Dropout(params['dropout']),\n",
    "        Bidirectional(LSTM(params['lstm_units_2'])),\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Função para inverter escala\n",
    "    def inverse_transform(scaler, data):\n",
    "        dummy = np.zeros((len(data), n_features))\n",
    "        dummy[:, 0] = data.flatten()\n",
    "        return scaler.inverse_transform(dummy)[:, 0]\n",
    "    \n",
    "    y_test_inv = inverse_transform(params['scaler'], y_test)\n",
    "    test_pred_inv = inverse_transform(params['scaler'], test_pred)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inv, test_pred_inv))\n",
    "    mae = mean_absolute_error(y_test_inv, test_pred_inv)\n",
    "    \n",
    "    return rmse, mae, history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248857d6",
   "metadata": {},
   "source": [
    "\n",
    "Este trecho de código é responsável por coletar os dados históricos da ação, enriquecer com indicadores técnicos e preparar os dados em formato adequado para o treinamento de um modelo de aprendizado profundo.\n",
    "\n",
    "---\n",
    "\n",
    "### 📥 Coleta de Dados com o `yfinance`\n",
    "\n",
    "```python\n",
    "df = yf.download(symbol, period=period, interval=interval, progress=True)\n",
    "df.columns = df.columns.droplevel(1)\n",
    "```\n",
    "\n",
    "- Utiliza a biblioteca `yfinance` para baixar dados históricos de preços do ativo definido pela variável `symbol`.\n",
    "- `period` define o intervalo temporal (ex: `\"2y\"`).\n",
    "- `interval` define a granularidade (ex: `\"1d\"`, `\"1h\"`).\n",
    "- Algumas vezes os dados retornam com MultiIndex; `droplevel(1)` limpa isso.\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 Enriquecimento com Indicadores Técnicos\n",
    "\n",
    "```python\n",
    "df = add_technical_indicators(df)\n",
    "df.dropna(inplace=True)\n",
    "```\n",
    "\n",
    "- A função `add_technical_indicators(df)` insere colunas com indicadores de momentum, tendência, volatilidade, volume e padrões de candle.\n",
    "- Após o cálculo dos indicadores, valores iniciais podem conter `NaN` devido às janelas móveis → são removidos com `dropna`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Seleção das Features\n",
    "\n",
    "```python\n",
    "available_features = [ ... ]\n",
    "features = [f for f in available_features if f in df.columns]\n",
    "df = df[features]\n",
    "```\n",
    "\n",
    "- Define um conjunto completo de **variáveis de entrada candidatas** (features) para o modelo.\n",
    "- Utiliza uma verificação para garantir que apenas as colunas calculadas de fato (que existem em `df`) sejam usadas.\n",
    "- Garante consistência e evita erros caso alguma feature falhe durante o cálculo.\n",
    "\n",
    "#### As features selecionadas incluem:\n",
    "- **Preços e volume básicos**: `Open`, `High`, `Low`, `Close`, `Volume`.\n",
    "- **Indicadores técnicos de momentum**: `RSI`, `Stoch_K`, `Stoch_D`, `Awesome_Oscillator`.\n",
    "- **MACD e seus componentes**: `MACD`, `MACD_signal`, `MACD_diff`.\n",
    "- **Indicadores de tendência**: `CCI`, `ADX`, `ADX_pos`, `ADX_neg`.\n",
    "- **Bandas de Bollinger**: `BB_upper`, `BB_middle`, `BB_lower`.\n",
    "- **Média móvel**: `EMA_20`.\n",
    "- **Volatilidade**: `ATR`.\n",
    "- **Volume inteligente**: `VWAP`, `OBV`, `AccDistIndex`.\n",
    "- **Padrões de candle**: `Candle_Body`, `Candle_Range`, `Upper_Shadow`, `Lower_Shadow`.\n",
    "\n",
    "---\n",
    "\n",
    "### ✂️ Divisão Treino/Teste com Normalização\n",
    "\n",
    "```python\n",
    "def prepare_data(df, seq_length=SEQ_LENGTH_DEFAULT):\n",
    "    num_samples = len(df) - seq_length - 1\n",
    "    train_size = int(num_samples * (1 - TEST_SIZE))\n",
    "    \n",
    "    df_train = df.iloc[:train_size + seq_length + 1].copy()\n",
    "    df_test = df.iloc[train_size:].copy()\n",
    "```\n",
    "\n",
    "- Define a proporção de treino/teste com base na constante `TEST_SIZE` (ex: 0.2).\n",
    "- Garante que tanto o conjunto de treino quanto o de teste contenham sequências completas (`+ seq_length + 1`).\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Normalização com `MinMaxScaler`\n",
    "\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train)\n",
    "train_scaled = scaler.transform(df_train)\n",
    "test_scaled = scaler.transform(df_test)\n",
    "```\n",
    "\n",
    "- Aplica a **normalização MinMax** nos dados, transformando os valores para a faixa `[0, 1]`.\n",
    "- **Importante**: o scaler é treinado **apenas com dados de treino**, para evitar vazamento de informação (`data leakage`).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 Criação das Sequências Temporais\n",
    "\n",
    "```python\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "```\n",
    "\n",
    "- Gera os conjuntos de entrada (`X`) e saída (`y`) para o modelo, com base nas janelas de `seq_length` períodos.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔚 Retorno da Função\n",
    "\n",
    "```python\n",
    "return X_train, y_train, X_test, y_test, scaler\n",
    "```\n",
    "\n",
    "- A função retorna os dados processados e prontos para o treinamento, além do `scaler`, que será necessário para inverter a normalização após a predição.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Contexto da Prova de Conceito (PoC)\n",
    "\n",
    "Este pipeline de preparação de dados foi desenvolvido no contexto de uma **prova de conceito (PoC)** uti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(symbol, period=period, interval=interval, progress=True)\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "df = add_technical_indicators(df)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "available_features = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',             # Preços e volume básicos\n",
    "    'RSI', 'Stoch_K', 'Stoch_D', 'Awesome_Oscillator',    # Indicadores de momentum\n",
    "    'MACD', 'MACD_signal', 'MACD_diff',                   # MACD\n",
    "    'CCI', 'ADX', 'ADX_pos', 'ADX_neg',                   # Indicadores de tendência\n",
    "    'BB_upper', 'BB_middle', 'BB_lower',                  # Bandas de Bollinger\n",
    "    'EMA_20',                                             # Média móvel exponencial\n",
    "    'ATR',                                                # Volatilidade\n",
    "    'VWAP', 'OBV', 'AccDistIndex',                        # Indicadores de volume\n",
    "    'Candle_Body', 'Candle_Range', 'Upper_Shadow', 'Lower_Shadow'  # Candlestick features\n",
    "]\n",
    "\n",
    "features = [f for f in available_features if f in df.columns]\n",
    "print(\"Features selecionadas:\", features)\n",
    "\n",
    "df = df[features]\n",
    "\n",
    "# --- Divisão treino/teste ---\n",
    "def prepare_data(df, seq_length=SEQ_LENGTH_DEFAULT):\n",
    "    num_samples = len(df) - seq_length - 1\n",
    "    train_size = int(num_samples * (1 - TEST_SIZE))\n",
    "    df_train = df.iloc[:train_size + seq_length + 1].copy()\n",
    "    df_test = df.iloc[train_size:].copy()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train)\n",
    "    train_scaled = scaler.transform(df_train)\n",
    "    test_scaled = scaler.transform(df_test)\n",
    "    \n",
    "    X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "    X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8731495",
   "metadata": {},
   "source": [
    "## 🔧 Busca Randomizada de Hiperparâmetros para Modelos LSTM\n",
    "\n",
    "Este bloco de código realiza uma **busca aleatória (random search)** para encontrar a melhor combinação de hiperparâmetros de um modelo LSTM bidirecional, visando minimizar o erro RMSE (Root Mean Squared Error) na previsão de preços de ativos financeiros.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Objetivo da Otimização\n",
    "\n",
    "Selecionar, entre diferentes combinações de hiperparâmetros, aquela que oferece o melhor desempenho em termos de RMSE sobre o conjunto de teste. O processo explora o espaço de configurações e compara os resultados, armazenando o melhor modelo encontrado.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 Definição do Espaço de Busca\n",
    "\n",
    "```python\n",
    "search_space = {\n",
    "    'seq_length': [12, 24, 36, 48, 60],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'epochs': [50, 80, 100, 120, 150],\n",
    "    'lstm_units_1': [64, 128, 256, 384, 512],\n",
    "    'lstm_units_2': [32, 64, 128, 192, 256],\n",
    "    'dropout': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005]  \n",
    "}\n",
    "```\n",
    "\n",
    "- Define os valores possíveis para cada hiperparâmetro.\n",
    "- **`seq_length`**: Número de observações anteriores usadas como entrada.\n",
    "- **`batch_size`**: Quantidade de amostras processadas por iteração.\n",
    "- **`epochs`**: Número máximo de ciclos de treinamento.\n",
    "- **`lstm_units_1`/`lstm_units_2`**: Número de neurônios nas camadas LSTM bidirecionais.\n",
    "- **`dropout`**: Fração de unidades descartadas durante o treinamento para evitar overfitting.\n",
    "- **`learning_rate`**: Taxa de aprendizado usada pelo otimizador `Adam`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Processo de Busca Aleatória\n",
    "\n",
    "```python\n",
    "n_trials = 10\n",
    "best_rmse = float('inf')\n",
    "```\n",
    "\n",
    "- Define `n_trials` como o número total de execuções (combinações aleatórias a serem testadas).\n",
    "- Inicializa a variável `best_rmse` como infinito, para garantir que qualquer RMSE válido será menor.\n",
    "\n",
    "---\n",
    "\n",
    "### 📦 Loop de Execuções\n",
    "\n",
    "```python\n",
    "for trial in range(n_trials):\n",
    "    params = {\n",
    "        'seq_length': random.choice(...),\n",
    "        ...\n",
    "    }\n",
    "```\n",
    "\n",
    "- Para cada tentativa:\n",
    "  - Seleciona **aleatoriamente** um valor para cada hiperparâmetro a partir do `search_space`.\n",
    "  - Armazena os valores selecionados no dicionário `params`.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Preparação de Dados com `prepare_data`\n",
    "\n",
    "```python\n",
    "X_train, y_train, X_test, y_test, scaler = prepare_data(df, seq_length=params['seq_length'])\n",
    "params['scaler'] = scaler\n",
    "```\n",
    "\n",
    "- Os dados são normalizados e divididos com base no `seq_length` escolhido.\n",
    "- O `scaler` é salvo dentro de `params` para permitir a inversão da escala posteriormente.\n",
    "\n",
    "---\n",
    "\n",
    "### 🏋️‍♂️ Treinamento e Avaliação\n",
    "\n",
    "```python\n",
    "rmse, mae, history, model = train_and_evaluate(...)\n",
    "```\n",
    "\n",
    "- Treina o modelo LSTM com os hiperparâmetros atuais.\n",
    "- Avalia seu desempenho utilizando métricas padronizadas:\n",
    "  - **RMSE (Root Mean Squared Error)**: penaliza erros maiores.\n",
    "  - **MAE (Mean Absolute Error)**: média dos erros absolutos.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Atualização do Melhor Modelo\n",
    "\n",
    "```python\n",
    "if rmse < best_rmse:\n",
    "    best_rmse = rmse\n",
    "    best_params = params\n",
    "    best_model = model\n",
    "    best_history = history\n",
    "```\n",
    "\n",
    "- Se o modelo atual tiver desempenho superior ao melhor até então:\n",
    "  - Salva os hiperparâmetros, o modelo treinado e o histórico de treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧾 Registro dos Resultados\n",
    "\n",
    "```python\n",
    "results.append({\n",
    "    'trial': trial + 1,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    **params\n",
    "})\n",
    "```\n",
    "\n",
    "- Armazena todas as métricas e os hiperparâmetros testados para posterior análise.\n",
    "\n",
    "---\n",
    "\n",
    "### 🏁 Resultados Finais\n",
    "\n",
    "```python\n",
    "print(\"\\nMelhor RMSE:\", best_rmse)\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "```\n",
    "\n",
    "- Exibe a melhor configuração encontrada após todos os testes realizados.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Considerações Técnicas\n",
    "\n",
    "- **Random Search** é menos eficiente que métodos baseados em gradiente ou Bayesian Optimization, mas útil em contextos onde:\n",
    "  - O custo de cada avaliação é alto.\n",
    "  - O espaço de busca é não contínuo.\n",
    "  - A função objetivo (modelo) é não diferenciável.\n",
    "\n",
    "- A randomização evita viés e permite cobrir melhor o espaço de busca do que uma simples busca em grade (grid search) quando o número de tentativas é limitado.\n",
    "\n",
    "- Este método é especialmente adequado para provas de conceito (PoC) e cenários com restrições de tempo computacional.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Relevância para Séries Temporais\n",
    "\n",
    "Em modelos baseados em LSTM para séries temporais:\n",
    "- Pequenas variações em `seq_length`, `lstm_units` ou `learning_rate` podem ter impacto significativo na capacidade do modelo de **capturar padrões de longo prazo**.\n",
    "- O uso de `Dropout` ajuda a combater o overfitting, comum quando há correlação temporal elevada entre amostras adjacentes.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔬 Próximos Passos\n",
    "\n",
    "- Persistir os melhores resultados (parâmetros, métricas, modelo).\n",
    "- Visualizar o `history` de treinamento (loss x epochs).\n",
    "- Avaliar generalização para novos dados (validação out-of-sample).\n",
    "- Implementar uma busca **Bayesiana** com `Optuna` ou `KerasTuner` para refinamento posterior.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55248a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Espaço de hiperparâmetros para busca ---\n",
    "search_space = {\n",
    "    'seq_length': [12, 24, 36, 48, 60],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'epochs': [50, 80, 100, 120, 150],\n",
    "    'lstm_units_1': [64, 128, 256, 384, 512],\n",
    "    'lstm_units_2': [32, 64, 128, 192, 256],\n",
    "    'dropout': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005]  \n",
    "}\n",
    "\n",
    "# --- Busca randomizada ---\n",
    "n_trials = 10  # quantas combinações testar\n",
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "best_model = None\n",
    "best_history = None\n",
    "results = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    params = {\n",
    "        'seq_length': random.choice(search_space['seq_length']),\n",
    "        'batch_size': random.choice(search_space['batch_size']),\n",
    "        'epochs': random.choice(search_space['epochs']),\n",
    "        'lstm_units_1': random.choice(search_space['lstm_units_1']),\n",
    "        'lstm_units_2': random.choice(search_space['lstm_units_2']),\n",
    "        'dropout': random.choice(search_space['dropout']),\n",
    "        'learning_rate': random.choice(search_space['learning_rate']),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTrial {trial+1}/{n_trials} com params: {params}\")\n",
    "    \n",
    "    # Preparar dados para o seq_length atual\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_data(df, seq_length=params['seq_length'])\n",
    "    params['scaler'] = scaler\n",
    "    \n",
    "    # Treinar e avaliar\n",
    "    try:\n",
    "        rmse, mae, history, model = train_and_evaluate(X_train, y_train, X_test, y_test, params, n_features=len(features))\n",
    "        print(f\"RMSE: {rmse:.4f} - MAE: {mae:.4f}\")\n",
    "        \n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            best_history = history\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no treino/avaliação: {e}\")\n",
    "        \n",
    "results.append({\n",
    "    'trial': trial + 1,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    **params  # isso inclui todos os hiperparâmetros testados\n",
    "})\n",
    "\n",
    "print(\"\\nMelhor RMSE:\", best_rmse)\n",
    "print(\"Melhores hiperparâmetros:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092c328",
   "metadata": {},
   "source": [
    "| O código plota um gráfico que compara os preços reais de fechamento com as previsões feitas pelo melhor modelo treinado. Para isso, ele primeiro reverte a escala dos dados normalizados para valores reais, tanto para os dados de teste quanto para as previsões, utilizando o mesmo scaler. Em seguida, exibe essa comparação visualmente, permitindo avaliar a precisão do modelo na previsão dos preços ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotar resultado com melhor modelo ---\n",
    "if best_model:\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_data(df, seq_length=best_params['seq_length'])\n",
    "    y_test_inv = scaler.inverse_transform(\n",
    "        np.concatenate([y_test.reshape(-1,1), np.zeros((len(y_test), len(features)-1))], axis=1)\n",
    "    )[:, 0]\n",
    "    \n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_pred_inv = scaler.inverse_transform(\n",
    "        np.concatenate([test_pred, np.zeros((len(test_pred), len(features)-1))], axis=1)\n",
    "    )[:, 0]\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(y_test_inv, label='Valor Real')\n",
    "    plt.plot(test_pred_inv, label='Previsão')\n",
    "    plt.title(f'Previsão do Preço de Fechamento - {symbol} (Melhor Modelo)')\n",
    "    plt.xlabel('Horas')\n",
    "    plt.ylabel('Preço (R$)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90174264",
   "metadata": {},
   "source": [
    "| Após o treinamento do modelo e a obtenção dos melhores resultados, é fundamental salvar o modelo para que ele possa ser reutilizado posteriormente sem a necessidade de ser re-treinado. O formato .h5 é amplamente utilizado em projetos que envolvem modelos Keras/TensorFlow, pois permite armazenar tanto a arquitetura quanto os pesos do modelo em um único arquivo. Isso facilita a implantação, compartilhamento e posterior análise do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o melhor modelo em formato HDF5 (.h5)\n",
    "if best_model:\n",
    "    best_model.save('../model/modelo_v1.h5')\n",
    "    print(\"Modelo salvo com sucesso no arquivo 'best_lstm_model.h5'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
